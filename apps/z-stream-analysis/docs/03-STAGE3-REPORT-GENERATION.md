# Stage 3: Report Generation (report.py)

Converts AI analysis results into human-readable reports.

---

## Overview

**Command:**
```bash
python -m src.scripts.report <run_dir>
python -m src.scripts.report runs/acm-e2e_20260205_120000
```

**Input:** `analysis-results.json` (from Stage 2) + `core-data.json` (from Stage 1)

**Output:** Three report files in the run directory

```
analysis-results.json ──┐
                        ├──► ReportFormatter ──┬── Detailed-Analysis.md
core-data.json ─────────┘                     ├── per-test-breakdown.json
                                              └── SUMMARY.txt
```

**Class:** `ReportFormatter` in `src/scripts/report.py`

---

## Input Detection Logic

`ReportFormatter` auto-detects the data format when loading:

```
1. manifest.json exists?
   └── YES → load core-data.json (multi-file mode)

2. raw-data.json exists?
   ├── Has _migration_version? → load core-data.json (migration stub)
   └── No migration field? → use raw-data.json as-is (legacy mode)

3. Neither? → try core-data.json directly
4. Nothing found? → raise FileNotFoundError
```

This allows the report generator to work with both current (v2.4+) and older run directories.

---

## Schema Validation

Before generating reports, `ReportFormatter` validates `analysis-results.json` against the JSON Schema at `src/schemas/analysis_results_schema.json` using `SchemaValidationService`.

| Outcome | Behavior |
|---------|----------|
| Valid, no warnings | Proceeds silently |
| Valid with warnings | Logs warning count, proceeds |
| Invalid | Logs validation issues, proceeds anyway (best-effort) |
| SchemaValidationService unavailable | Skips validation, proceeds |

---

## Report Generation Flow

```
┌─────────────────────────────────────────────────────────┐
│  ReportFormatter.__init__(run_dir)                      │
│                                                         │
│  1. _load_core_data()  → self.raw_data                  │
│  2. _load_json('analysis-results.json') → self.analysis │
│  3. _validate_analysis_results()                        │
└───────────────────────┬─────────────────────────────────┘
                        │
                        ▼
┌─────────────────────────────────────────────────────────┐
│  format_all()                                           │
│                                                         │
│  ├── format_markdown()  → Detailed-Analysis.md          │
│  ├── format_json()      → per-test-breakdown.json       │
│  └── format_summary()   → SUMMARY.txt                   │
└───────────────────────┬─────────────────────────────────┘
                        │
                        ▼
             ┌──────────────────────┐
             │  Cleanup repos/      │
             │  (unless --keep-repos)│
             └──────────────────────┘
```

---

## Output: Detailed-Analysis.md

Generated by `format_markdown()`. The main human-readable report.

**Sections:**

| # | Section | Data Source |
|---|---------|-------------|
| 1 | Header | `metadata.jenkins_url`, `metadata.gathered_at` |
| 2 | Executive Summary | `summary.overall_classification`, `summary.overall_confidence`, `test_report.summary` |
| 3 | Classification Breakdown | `summary.by_classification` (sorted by count descending) |
| 4 | Build Information | `jenkins.job_name`, `jenkins.build_number`, `jenkins.build_result`, `jenkins.branch`, `jenkins.commit_sha` |
| 5 | Individual Test Failures | `per_test_analysis[]` — classification, confidence, error, reasoning, evidence, recommended fix |
| 6 | Common Patterns | `common_patterns[]` |
| 7 | Recommended Actions | `summary.priority_order[]` — sorted by priority |
| 8 | Environment Status | `environment.cluster_connectivity`, `environment.api_accessibility`, `environment.environment_score` |

**Fallback:** If `analysis-results.json` is missing, the report uses `test_report.failed_tests[]` with preliminary classifications from Stage 1 data.

**Example excerpt:**

```markdown
# Pipeline Failure Analysis Report

**Generated:** 2026-02-05 12:30:00
**Jenkins URL:** https://jenkins.example.com/job/acm-e2e/123/

---

## Executive Summary

| Metric | Value |
|--------|-------|
| **Overall Classification** | AUTOMATION BUG |
| **Confidence** | 92% |
| **Total Tests** | 150 |
| **Failed** | 3 |
| **Pass Rate** | 98.0% |

### Classification Breakdown

- AUTOMATION BUG: 2 test(s)
- PRODUCT BUG: 1 test(s)

---

## Individual Test Failures

### 1. should create cluster successfully

**File:** `cypress/e2e/cluster/create.cy.ts`

| Property | Value |
|----------|-------|
| **Classification** | AUTOMATION BUG |
| **Confidence** | 92% |

**Error:**
\```
Timed out: Expected to find element: '#create-btn', but never found it.
\```

**Analysis:** Selector '#create-btn' not found in product code...
```

---

## Output: per-test-breakdown.json

Generated by `format_json()`. Structured data for downstream tooling.

**Structure:**

```json
{
  "metadata": {
    "jenkins_url": "https://jenkins.example.com/job/acm-e2e/123/",
    "generated_at": "2026-02-05T12:30:00",
    "data_source": "analysis-results.json"
  },
  "summary": {
    "overall_classification": "AUTOMATION_BUG",
    "overall_confidence": 0.92,
    "by_classification": { "AUTOMATION_BUG": 2, "PRODUCT_BUG": 1 },
    "priority_order": [...]
  },
  "per_test_breakdown": [
    {
      "test_name": "should create cluster successfully",
      "classification": "AUTOMATION_BUG",
      "confidence": 0.92,
      "evidence_sources": [...],
      "reasoning": "...",
      "recommended_fix": "..."
    }
  ],
  "raw_test_data": [...],
  "test_summary": {
    "total_tests": 150,
    "passed_count": 147,
    "failed_count": 3,
    "pass_rate": 98.0
  }
}
```

---

## Output: SUMMARY.txt

Generated by `format_summary()`. Quick-glance text summary.

**Example:**

```
============================================================
PIPELINE FAILURE ANALYSIS SUMMARY
============================================================

Jenkins URL: https://jenkins.example.com/job/acm-e2e/123/
Build: acm-qe-e2e-nightly #123
Result: UNSTABLE

TEST SUMMARY:
  Total: 150
  Passed: 147
  Failed: 3
  Pass Rate: 98.0%

FAILURE BREAKDOWN:
  [AUTOMATION BUG]: 2 test(s)
  [PRODUCT BUG]: 1 test(s)

OVERALL: AUTOMATION BUG (92% confidence)

PRIORITY ACTIONS:
  1. [HIGH] should create cluster successfully...
  2. [MEDIUM] should display search results...

============================================================
See Detailed-Analysis.md for full report
============================================================
```

---

## Repo Cleanup

By default, `repos/` is deleted after report generation to save disk space. Cloned repositories can be 500MB+ and are no longer needed after analysis.

| Flag | Behavior |
|------|----------|
| (default) | Delete `repos/` after reports are written |
| `--keep-repos` | Preserve `repos/` directory |

---

## Emoji Reference

**Classification emoji** (used in Detailed-Analysis.md):

| Classification | Emoji |
|----------------|-------|
| PRODUCT_BUG | red circle |
| AUTOMATION_BUG | yellow circle |
| INFRASTRUCTURE | blue circle |
| UNKNOWN | white circle |
| REQUIRES_INVESTIGATION | white circle |
| NO_BUG | green circle |
| FLAKY | green circle |

MIXED is not in `CLASSIFICATION_EMOJI` — any unlisted classification gets the default white circle.

**Priority emoji** (used in Recommended Actions):

| Priority | Emoji |
|----------|-------|
| CRITICAL | red circle |
| HIGH | orange circle |
| MEDIUM | yellow circle |
| LOW | green circle |

---

## CLI Options

```bash
# Basic usage
python -m src.scripts.report <run_dir>

# Alternative flag syntax
python -m src.scripts.report --run-dir <run_dir>
python -m src.scripts.report -r <run_dir>

# Keep repos directory
python -m src.scripts.report <run_dir> --keep-repos
python -m src.scripts.report <run_dir> -k
```

**Exit codes:**

| Code | Meaning |
|------|---------|
| 0 | Reports generated |
| 1 | Error (directory not found, no data files, etc.) |

---

## CLI Output

The script prints progress indicators:

```
============================================================
STAGE 3: REPORT GENERATION
============================================================

[1/3] Loading analysis results...
[2/3] Generating reports...
[3/3] Finalizing...

============================================================
REPORTS GENERATED
============================================================
  markdown: runs/acm-e2e_20260205_120000/Detailed-Analysis.md
  json: runs/acm-e2e_20260205_120000/per-test-breakdown.json
  summary: runs/acm-e2e_20260205_120000/SUMMARY.txt

Cleaned up repos/ to save disk space (use --keep-repos to preserve)

============================================================
```
